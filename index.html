<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Chun Feng</title>
  
  <meta name="author" content="Chun Feng">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:65%;vertical-align:middle">
              <p style="text-align:center">
                <name>Chun Feng | ÂÜØÊ§ø</name>
              </p>
              <p>
                I am a senior undergraduate student in the School of Information Science and Technology at the <a href="http://en.ustc.edu.cn/">University of Science and Technology of China</a>. 
              </p>
	      <p>
                Last summer, I was a summer intern working with Prof. <a href="https://jiajunwu.com/">Jiajun Wu</a> at Stanford University on 3D object grounding. We tried to minimize human supervision and leverage commonsense knowledge to guide reasoning. 
              </p>
	      <p>
                I am also fortunate to work with Prof. <a href="https://www.chuatatseng.com/">Tat-Seng Chua</a> at the National University of Singapore on vision and language. 
              </p>
              
              <p style="text-align:center">
                <a href="mailto:fengchun3364@mail.ustc.edu.cn">Email: fengchun3364@mail.ustc.edu.cn</a> 
		<!-- <a href="mailto:fengchun3364@mail.ustc.edu.cn">Email: fengchun3364@mail.ustc.edu.cn</a> &nbsp/&nbsp -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/chunfeng.jpg">
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><u>Research</u></heading>
              <p>
                I'm broadly interested in video and 3D vision, with the goal of making the agents perceive the physical world and reason based on its perception. I'm also excited to explore other interesting topics (especially generative models).
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <img src="images/rcl.png" width="100%" style="border-style: none">
            </td>
            <td width="70%" valign="middle">
              <papertitle>Classification-Free 3D Object Grounding with Regularized Concept Learners</papertitle>
              <br>
              <strong>Chun Feng*</strong>,
              <a href="https://web.stanford.edu/~joycj/">Joy Hsu*</a>,
              <a href="http://weiyuliu.com/">Weiyu Liu</a>,
              <a href="https://jiajunwu.com/">Jiajun Wu</a>
              <br>
              <em>Under review</em>
              <br>
              <a href="https://drive.google.com/file/d/1vjqMSDFdUJv_QwwZFEMvmFUDNBDPrcaE/view?usp=sharing">PDF</a> /
              <a href="https://chunfeng3364.github.io/">code</a>
              <p>We propose TranSTR that features a spatio-temporal rationalization (STR) module together with a more reasonable candidate answer modeling strategy. The answer modeling strategy is independently verified to be effective in boosting other existing VideoQA models.</p>
              <br>
            </td>
          </tr>
		
	  <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <img src="images/spatiotemporal.png" width="100%" style="border-style: none">
            </td>
            <td width="70%" valign="middle">
              <papertitle>Discovering Spatio-Temporal Rationales for Video Question Answering</papertitle>
              <br>
              <a href="https://yl3800.github.io/">Yicong Li</a>,
              <a href="https://doc-doc.github.io/cv/">Junbin Xiao</a>,
              <strong>Chun Feng</strong>,
              <a href="https://xiangwang1223.github.io/">Xiang Wang</a>,
              <a href="https://www.chuatatseng.com/">Tat-Seng Chua</a>
              <br>
              <em>ICCV 2023</em>
              <br>
              <a href="https://arxiv.org/pdf/2307.12058v1.pdf">arXiv</a> /
              <a href="https://github.com/yl3800/TranSTR">code</a>
              <p>We propose TranSTR that features a spatio-temporal rationalization (STR) module together with a more reasonable candidate answer modeling strategy. The answer modeling strategy is independently verified to be effective in boosting other existing VideoQA models.</p>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <img src="images/redundancy.png" width="100%" style="border-style: none">
            </td>
            <td width="70%" valign="middle">
              <papertitle>Redundancy-aware Transformer for Video Question Answering</papertitle>
              <br>
              <a href="https://yl3800.github.io/">Yicong Li</a>,
              <a href="https://sites.google.com/site/xunyangprofile/">Xu Yang</a>,
	      <a href="https://anzhang314.github.io/">An Zhang</a>,
              <strong>Chunfeng</strong>,
              <a href="https://xiangwang1223.github.io/">Xiang Wang</a>,
              <a href="https://www.chuatatseng.com/">Tat-Seng Chua</a>
              <br>
              <em>ACM MM 2023</em>
              <br>
              <a href="https://arxiv.org/pdf/2308.03267.pdf">arXiv</a> 
              <p>We propose RaFormer, a fully transformer-based VideoQA model that avoids neighboring-frame redundancy by highlighting object-level change in adjacent frames and the out-of-neighborhood message passing at frame-level. In addition, it also handles the cross-modal redundancy via a novel adaptive sampling module.</p>
              <br>
            </td>
          </tr>

        </tbody></table>
        <br>


	<!--
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading><u>Industry</u></heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/tencent_ai_lab.png" width="100%" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Research Intern, Tencent AI Lab</papertitle>
              <br>
              June 2023 - Present
              <br>
              <p>Researching on 3D-consistent human body generation using diffusion models and autoencoders.</p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/gs.jpeg" width="100%" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Engineering Summer Analyst, Goldman Sachs</papertitle>
              <br>
              June 2022 - August 2022
              <br>
              <p>Developed and modularized a calculator for a loan product, <a href="https://welcome.gsselect.com/content/gsSelect/us/en/homepage.html">GS Select</a>, to automatically calculate a key financial metric, risk-weighted asset, on a daily frequency.</p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/bd.png" width="100%" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Software Engineer Intern, Bytedance</papertitle>
              <br>
              March 2021 - August 2021
              <br>
              <p>Optimized Tiktok's Android Package size and cold startup time, through developing
                optimization passes based on Facebook's open-source Android bytecode optimizer <a href="https://fbredex.com/">ReDex</a>.</p>
            </td>
          </tr>
        </tbody></table>
	-->


	<!--
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading><u>Misc</u></heading>
            <p>
              At UC Berkeley, I was a member of <a href="https://upe.berkeley.edu/">UPE</a> (CS Honor Society), <a href="https://pbk.berkeley.edu/">PBK</a> (Academic Honor Society), and <a href="https://awe.berkeley.edu/">AWE</a> (Association of Women in EE&CS). From 2020 to 2021, I served as the Director of the International Affairs Department in <a href="https://asuc.org/">ASUC</a> Senator <a href="https://asuc.org/rzhang/">Rex Zhang</a>'s office.
              <br><br>
              In my spare time, I enjoy watching movies and dining out. My top 3 movies are Before Sunrise, Blade Runner, and Infernal Affairs (Êó†Èó¥ÈÅì).
            </p>
          </td>
        </tr>
      </tbody></table>
      -->
	      

      
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Last updated: Dec 10, 2023
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
  

	
</body>

</html>
